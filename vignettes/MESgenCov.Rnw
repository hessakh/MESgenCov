%\VignetteEngine{knitr::knitr}
% !Rnw weave = knitr
%\VignetteIndexEntry{MESgenCov: An R Package for ...}

\documentclass[11pt]{article}
\usepackage[left=2.54cm, top=2.54cm, right=2.54cm, bottom=2.54cm]{geometry}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,array}
\usepackage{booktabs}
\usepackage{caption}
\usepackage{cite}
\usepackage{colortbl}
\usepackage{comment}
\usepackage{float}
\usepackage{hyperref}
\usepackage{longtable}
\usepackage{multirow}
\usepackage{pdflscape}
\usepackage{subcaption}
\usepackage[table]{xcolor}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage[normalem]{ulem}
\usepackage{wrapfig}


\title{MESgenCov: An R Package for generating covariance matrices \\ from precipitation chemistry data}
\author{Hessa Al-Thani$^1$ \qquad Jon Lee$^2$\\[0.35cm]
  {\small Dept. of Industrial and Operations Engineering, Univ. of Michigan, Ann Arbor, MI 48105 USA }\\[0.35cm]{\small{$^1$hessa.k.h9@gmail.com}} \qquad {\small{$^2$jonxlee@umich.edu}}
}
\date{\textbf{MESgenCov} \Sexpr{packageDescription("MESgenCov2")$Version}  }
%

\begin{document}

<<setup, include=FALSE, cache=FALSE>>=
library(knitr)
library(MESgenCov2)
@
<<include=FALSE>>=

@

\maketitle

\begin{abstract}
  We present an R package for temporally fitting multivariate precipitation chemistry data and extracting a covariance matrix
for use in MES (maximum-entropy sampling).
 We provide multiple functionalities for modeling and model assessment. The package uses data from the NADP/NTN (National Atmospheric Deposition Program / National Trends Network) on their set of more than 370 monitoring sites, 1978--present. The user specifies the sites, chemicals and time period desired, fits a user-defined univariate model for each site and chemical selected, and produces a covariance matrix for use by MES algorithms.

\end{abstract}

\section{The MES problem}

The MES (maximum-entropy sampling) problem (see \cite{ShewryWynn,SebWynn,FedorovLee,LeeEnv}) has been applied to many domains where the objective is to determine a most informative subset $S$, of presepcified size $s$, from a set of $n$ Gaussian variables $N$. This is done by seeking to maximize the (log) determinant of the covariance matrix for some $S \subseteq N$ with $|S|=s$ (see \cite{KLQ,LeeConstrained,AFLW_Using,LeeWilliams_ILP,HLW,AnstreicherLee_Masked,BurerLee,AnstreicherBQPEntropy,linx}). A key area of application has been in environmental montoring (see \cite{Zidek1,Zidek2,Zidek3}, for example).
In this R package, we use  precipitation chemistry data
(ammonium,
calcium,
chloride,
hydrogen,
 magnesium,
 nitrate,
pH,
 potassium,
  sodium, and
sulfate) gathered by the NADP (National Atmospheric Deposition Program) at over 370 sites across the U.S.A. (see \cite{NADPNTN}).
For these instances of the MES problem, $n$ \emph{user-specified} site/chemical pairs comprise $N$.
%%add a bit on generalized getCov after finishing the function

\section{NADP data description}

The NADP maintains the NTN (National Trends Network); this network measures the chemistry of precipitation at monitoring sites across the
U.S.A. Our R package makes use of the weekly data measuring  mg/L of chemicals, such as sulfates, in collected precipitation. We also use the daily data measuring precipitation at each site. Both datasets are available in our package and can be loaded respectively as


<<chunk1, include=TRUE>>=
 data("weeklyCSV")
 data("preDailyCSV")
@

A full description of the data can be obtained at \href{http://NADP.slh.wisc.edu/data/ntn/meta/ntn-weekly-Meta.pdf}{NADP/NTN weekly meta}. For a full description of the daily precipitation data, see \href{http://NADP.slh.wisc.edu/data/ntn/meta/ntn-daily-Meta.pdf}{NADP/NTN daily meta}. Small snapshots of the data can also be viewed using:

<<chunk2,include=TRUE>>=
  weeklyCSV[1:6,c(1:4,9)]
@

This outputs the first 6 rows, first 4 columns and 9th column of the weekly raw data, columns 5 to 8 contain data that isn't relevant to our analysis. 
\section{MESgenCov implementation}

 The \textbf{MESgenCov} package contains functions in the \texttt{S3} class to create a covariance matrix from the desired subset of NADP data. The function \verb;getCov(); returns a covariance matrix, a list of univariate model summaries, and a table of normality tests produced by the MVN R package. The covariance matrix is produced from a subset of the NADP/NTN data that is specified by the user. For sites with missing data, \verb;getCov(); will fill in predicted values based on the univariate model for each site (see section \ref{sec:3.1}). To avoid sites with a small sample size for the specified time-frame, the function \verb;getSites(); outputs a vector of the sites with the largest sample of data for a given time-frame and measured chemical (see section \ref{sec:3.2}). To find sites that are spatially ``spread out'' but have at least some specified sample size, the function \verb;maxDistSites(); can be used (see section \ref{sec:3.2}).

  \subsection{getCov}
  \label{sec:3.1}
  \verb;getCov(); has 18 inputs that allow the user to specify the subset of data to analyze and gives the user options in displaying different parts of the analysis. A table of the input is given here:

  %%table

  <<message=FALSE, echo=FALSE, warning=FALSE, eval=TRUE>>=
  text_tbl <- data.frame(
  Arguments = c("weeklyB", "startdateStr", "enddateStr", "use36", "siteAdd",  "outlierDatesbySite", "showOutliers", "siteOutliers", "comp", "plotMulti", "plotB", "sitePlot", "plotAll", "writeMat", "seas", "r", "k","p"),
  Definition = c( "TRUE if weekly data should be analyzed and FALSE if monthly data should be analyzed", "Date and time of when to start analyzing the data, in the format = “m/d/y H:M”", "Date and time of when to stop analyzing the data, in the format = “m/d/y H:M”", "TRUE if default 36 sites should be added, FALSE otherwise", "Vector of strings of siteIDs", "Vector of time periods for specific sites (e.g. month 1 for VT01) to exclude from analysis", "TRUE if outliers of a specific site should be displayed", "Specify siteID string for outlier analysis", "Vector of strings of pollutants or acidity levels to be analyzed, the pollutants name should be used as it appears in weeklyCSV", "TRUE if multivariate analysis plots should be displayed, FALSE otherwise", "TRUE if plots of specific sites should be displayed", "Specify siteID to be plotted", "TRUE if plots for all sites should be displayed, FALSE otherwise", "TRUE if  .mat file of the resulting covariance matrix should be written in the working directory", "Approximate periodicity of data, typically 12 for monthly data and 52 for weekly data", "Integer <=5, see univariate model","Integer <= 5, see univariate model","Integer <= 5, see univariate model"
  )
  )
@

<<message=FALSE, echo=FALSE, warning=FALSE, eval=TRUE>>=
library(magrittr)
library(kableExtra)
    kable(text_tbl, format = "latex", booktabs = T) %>%
    kable_styling(full_width = F) %>%
    column_spec(1, bold = T, color = "black") %>%
    column_spec(2, width = "30em") %>%
        kable_styling(latex_options = "striped")
@

The function \texttt{getCov} produces the following outputs:
\begin{enumerate}

\item Multivariate and univariate normality
<<chunckCovMult,include=TRUE,eval=FALSE>>=
    g2 <-getCov(FALSE,"01/01/83 00:00", "12/31/88 00:00",TRUE,NULL,NULL,
         NULL,TRUE,"IN41SO4","SO4",FALSE,TRUE,"IN41",FALSE,FALSE,12,1,3,1)
@

\begin{center}
\includegraphics[width = 75mm]{pic1GetCov}
\end{center}

% Remove suggested outliers
% <<chunckCovMultOut,include=TRUE,eval=FALSE>>=
%   getCov(FALSE,"01/01/83 00:00", "12/31/89 00:00",TRUE,NULL,c(1,2,3),NULL,
%          FALSE,NULL,"SO4",TRUE,TRUE,"OH49",FALSE,FALSE,12,1,3,1)
% @
%%add figure of code ^^

<<chunckCuni,include=TRUE,eval=FALSE>>=
    g2$univariateTest
@
%%

\begin{center}
\includegraphics[width = 75mm]{g2univ}
\end{center}


\item Outlier test for specific tests
<<chunckCovSite,include=TRUE,eval=FALSE>>=
g2<-getCov(FALSE,"01/01/83 00:00", "12/31/88 00:00",TRUE,c("OH71","NY08"),NULL,
           NULL,TRUE,"IN41SO4","SO4",FALSE,TRUE,"IN41",FALSE,FALSE,12,1,3,1)
g2$rosnerTest
@
%%
\begin{center}
\includegraphics[width = 70mm]{rosnerTest}
\end{center}



By changing the input we can remove the outliers detected by the rosner test
%bottom code should be based on actual outliers, make sure to change accordingly!
<<chunckCovSiteOutremoved,include=TRUE,eval=FALSE>>=
  getCov(FALSE,"01/01/83 00:00", "12/31/86 00:00",TRUE,c("OH71","NY08"),NULL,
         c("IN41",25),TRUE,"IN41SO4","SO4",FALSE,FALSE,NULL,FALSE,
         FALSE,12,1,3,1)
@
\begin{center}
\includegraphics[width = 75mm]{IN41trans}
\end{center}


\item Plot all sites
<<chunckCovPlotALL,include=TRUE,eval=FALSE>>=
  getCov(FALSE,"01/01/83 00:00", "12/31/86 00:00",TRUE,c("OH71","NY08"),NULL,
         c("OH71",1),TRUE,"OH71","SO4",FALSE,FALSE,NULL,FALSE,FALSE,12,1,3,1)
@

\begin{center}
  \includegraphics[width=75mm]{plotAll}
\end{center}

\item Covariance matrix
%%%%Parsing results
<<chunkCovResult,include=TRUE,eval=TRUE>>=
  result <- getCov(FALSE,"01/01/83 00:00", "12/31/86 00:00",FALSE,
                   c("OH71", "NY08", "WV18", "MI53", "NH02"),c(1,2,3,4),NULL,
                   FALSE,NULL,"SO4",FALSE,FALSE,NULL,FALSE,FALSE,12,1,3,1)
  round(result$cov,digits = 4)
@

\item Save covariance matrix as .mat file

This is done by simply setting the 5th last input to TRUE then the .mat file will be saved to the user's current working directory.

<<chunkCovMat,include=TRUE,eval=FALSE>>=
  result <- getCov(FALSE,"01/01/83 00:00", "12/31/86 00:00",FALSE,
                   c("OH71", "NY08", "WV18", "MI53", "NH02"),c(1,2,3,4),NULL,
                   FALSE,NULL,"SO4",FALSE,FALSE,NULL,FALSE,TRUE,12,1,3,1)
@



\item Univariate model summaries
%%%%Parsing results
<<chunkListModResult,include=TRUE,eval=TRUE>>=
  result <- getCov(FALSE,"01/01/83 00:00", "12/31/86 00:00",FALSE,
                   c("OH71", "NY08", "WV18", "MI53", "NH02"),c(1,2,3,4),
                   NULL,FALSE,NULL,"SO4",FALSE,FALSE,NULL,FALSE,FALSE,12,1,3,1)
  sites <- result$sites
  il = match(c("OH71"),sites)
  result$listMod[il]
@

\item Output all MVN package analysis\\
\noindent
\\
\noindent
The following output is a call to the MVN package that produces mutivariate analysis based on the Mardia method, univariate analysis based on the Shapiro-Wilson method and an multivariate outlier test that is presented as a plot and not as an output in the user's R console.



<<chunkMVNResult,include=TRUE,eval=TRUE>>=
  result <- getCov(FALSE,"01/01/83 00:00", "12/31/86 00:00",FALSE,
                   c("OH71", "WV18", "MI53"),c(1,2,3,4),NULL,
                   FALSE,NULL,"SO4",FALSE,FALSE,NULL,FALSE,FALSE,12,1,3,1)
  result$mvn
@

The specific call the the MVN package is,

<<chunkMVNcall,include=TRUE,eval=FALSE>>=
 mvn(dfRes[,-1], subset = NULL, mvnTest = "mardia", covariance = TRUE, 
     tol = 1e-25, alpha = 0.5, scale = FALSE, desc = TRUE, transform = "none", 
     univariateTest = "SW",  univariatePlot = "none", multivariatePlot ="none", 
     multivariateOutlierMethod = "none", bc = FALSE, bcType = "rounded", 
     showOutliers = FALSE, showNewData = FALSE).

@

See \cite{MVN} for details on the MVN package.
\end{enumerate}


  \subsection{Functions for getting a vector of sites}
    \label{sec:3.2}
 \texttt{getCov()} takes site lists as input, the function \texttt{getSites()} produces a list of sites with available data for a specified time frame. The code below produces a list of 36 sites with the most weekly data between the years 1983-1986. 

<<getSites1,include=TRUE,eval=TRUE>>=
  result <- getSites("01/01/83 00:00", "12/31/86 00:00",36,104,"SO4","")
  result$finalList
@

The 4th input specifies the minimum sample of weekly data required to be included in the produced list and the last input tells the function to only look at sites in the North Eastern region of the US. Other options for region "W","S","N", see Appendix A for the precise geographic split. 

<<getSites1region,include=TRUE,eval=TRUE>>=
  NESites <- getSites("01/01/83 00:00", "12/31/86 00:00",36,104,"SO4","NE")
  NESites$finalList
@

The function \texttt{maxDistSites()} prioritizes sites that are farther away from each other.

<<maxDistSites1,include=TRUE,eval=FALSE>>=
  maxDistSites("01/01/83 00:00", "12/31/86 00:00",36,104,"SO4",1)
@

\section{Methodology}
  \subsection{NADP data processing}
  We process the raw NADP data in a similar way to earlier uses in the context of the MES problem in the field of environmental statistics.
  \cite{Zidek3}
 analyzes the levels of a chemical's concentration by summing weekly quantities (mg) of the chemical, over a month,
 and dividing the monthly total by total precipitation (L), over dates in that month, to get monthly values of sulfate concentration (mg/L).
 For a given monitoring site, chemical, and month $t=0,1,\ldots,T-1$, let
      \begin{align*}
        W(t) &:= \text{set of weeks in month $t$,}\\
        D(w) &:= \text{set of days in week $w$,} \\
        c_w  &:= \text{recorded chemical concentration (mg/L) for week $w$}\\
             &\phantom{:=} \text{ ($c_w=*$ denotes an unrecorded value),}\\
        p_d  &:= \text{recorded precipitation quantity (L) for day $d$,}\\
        p_w  &:= \text{precipitation quantity (L) for week $w$; $\textstyle p_w=\sum_{d\in D(w)}p_d$.}
    \end{align*}
Then the chemical's concentration (mg/L) for month $t$ is calculated as
\[
y(t):=\frac{\sum_{w\in W(t) : c_w \not=*} p_w c_w}
{\sum_{w\in W(t) : c_w \not=*} \sum_{d\in w} p_d}.
\]
It should be noted that when there is no weekly value available for the chemical quantity,
    we do not use the preciptation values for any of the days in such a week
    (so as to not artificially dilute the chemical concentration level for the month).

Finally, a model is fit to $\log(y(t))$.
      In \cite{Zidek3} they use the following model to deseasonalize and detrend the data set of log transformed monthly sulfate concentration values.

\begin{equation} \label{simplemodel}
         \log(y(t))\approx \beta_{1} + \beta_{2}t + \beta_{3}\cos\bigg(\frac{2\pi t}{12}\bigg) + \beta_{4}\sin\bigg(\frac{2\pi t}{12}\bigg)~.
\end{equation}
Basically, this is just an affine model $ \beta_{1} + \beta_{2}t$ plus
    a sinusoidal model with monthly periodicity and intercept $\beta_3$.


  We found that this model did well in normalizing the error for
  certain cites but some sites like "MD13" and "NC03" did not do as well. Rather than
  fix \eqref{simplemodel} as our model, we provide a more flexible model described in the next section.%also show figures for sites

  \subsection{The univariate model}
  %%Confirm that we should not write about what we tries, just what worked
  %%i.e. don't write about ARIMA model
%
%   Through a few experiments we saw that odd powers of trigonometric functions fit the data well but different sites fitted better with different powers of $\sin (\frac{2t\pi}{12})$. In which case we would have had to fit a non-linear regression, to avoid this we use the fact that $\cos^p(t)$ has the following identities:r$
%   \begin{align}
%     \cos^3(t) & = \frac{3}{4}\cos(t) + \frac{1}{4}\cos(3t) \\
%     \cos^5(t) & = \frac{5}{8}\cos(t) + \frac{5}{16}\cos(3t) + \frac{1}{16}\cos(5t)
%   \end{align}
%
% Then we can fit the data at each site using:
%
%   \[\mu(s_i,t) = \beta_{1} + \sum_{i=1}^{r}\beta_{i}t^i + \sum_{j=1}^{k}\beta_{j3}\cos\bigg(\frac{2\pi tj}{S}\bigg) \tag{5}\]
%
% We also added the flexibility of deciding the periodicity of the function, the user can now alter the input $S$ to change the period of the model.
The general model that we provide is
\[
\log(y(t))\approx \sum_{i=0}^r \beta_{i}t^i + \sum_{j=1}^{k} \bigg[a_j \cos \bigg(\frac{2\pi jt}{S}\bigg) +  b_j \sin \bigg(\frac{2\pi jt}{S}\bigg)\bigg].
\]
The user can specify the degree $r$ for the polynomial part of the model which we think of as a truncated taylor series, aimed at capturing aperiodic trends.
Periodic trends are captured via a truncated Fourier series, truncated at level $k$.
The simple model \eqref{simplemodel} is this one with $r=1$, $k=1$ and $S=12$.



\section*{Acknowledgments} J. Lee was funded by the
Air Force Office of Scientific Research (Complex Networks program), FA9550-19-1-0175.
H. Al-Thani was funded by the Qatar National Research Fund (Graduate Sponsorship Research Program). The authors are very grateful to Dr. Martin Shafer and Robert Larson for helping us gain access to the NADP/NTN data in a convenient form.

\section{Appendix}
Appendix A
\begin{center}
\includegraphics[width = 60mm]{mapDivision}
\end{center}

\bibliographystyle{alpha}
\bibliography{MESgenCov2}

\end{document}


